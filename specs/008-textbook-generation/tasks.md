# Tasks: AI-Native Textbook with RAG Chatbot

**Input**: Design documents from `/specs/008-textbook-generation/`
**Prerequisites**: plan.md, spec.md, research.md, data-model.md, contracts/openapi.yaml

**Tests**: Not explicitly requested. Test tasks omitted.

**Organization**: Tasks grouped by user story. 6 user stories (US1-US6) across P1-P3 priority.

## Format: `[ID] [P?] [Story] Description`

- **[P]**: Can run in parallel (different files, no dependencies)
- **[Story]**: Which user story this task belongs to (e.g., US1, US2, US3)
- Include exact file paths in descriptions

---

## Phase 1: Setup (Shared Infrastructure)

**Purpose**: Project initialization, restructure directories, configure environment

- [x] T001 Create the 6-part docs directory structure with `_category_.json` files per plan.md in `docs/Part-1-introduction/`, `docs/Part-2-humanoid-robotics/`, `docs/Part-3-ros2/`, `docs/Part-4-digital-twin/`, `docs/Part-5-vla/`, `docs/Part-6-capstone/`
- [x] T002 Migrate existing chapter content from `hackathon-book/docs/` to the new `docs/` structure, remapping Part-1-ros2 content to Part-2 and Part-3, Part-2-gazebo-unity to Part-4, Part-3-isaac to Part-4, Part-4-vla-humanoids to Part-5, Part-5-hardware to Part-6 per research.md R-004
- [x] T003 [P] Update `docusaurus.config.ts` at repo root: set title to "Physical AI", set auto-generated sidebar (`type: 'autogenerated'`), update navbar, remove blog, configure Vercel deployment
- [x] T004 [P] Update `sidebars.ts` at repo root to use `type: 'autogenerated', dirName: '.'` for fully auto-generated sidebar from docs/ hierarchy
- [x] T005 [P] Update `backend/requirements.txt` to add: `psycopg2-binary`, `requests` (for HF API). Keep existing: `fastapi`, `uvicorn`, `qdrant-client`, `python-dotenv`, `google-genai`
- [x] T006 [P] Update `backend/.env.example` (create if not exists) with template variables: `QDRANT_URL`, `QDRANT_API_KEY`, `DATABASE_URL` (Neon), `HF_API_TOKEN`, `GEMINI_API_KEY`
- [x] T007 Update `src/pages/index.tsx` to show textbook title, brief introduction, and table of contents linking to all six parts

**Checkpoint**: Project restructured. Docs in 6-part hierarchy. Config updated. Dependencies declared.

---

## Phase 2: Foundational (Blocking Prerequisites)

**Purpose**: Core backend modules that ALL user stories depend on

**CRITICAL**: No user story work can begin until this phase is complete

- [x] T008 Create Hugging Face embedding client in `backend/embeddings.py` — function `embed_texts(texts: list[str]) -> list[list[float]]` that calls HF Inference API with `sentence-transformers/all-MiniLM-L6-v2`, returns 384-dim vectors, handles batching (max 32 texts per request), reads `HF_API_TOKEN` from env
- [x] T009 [P] Create Neon Postgres database module in `backend/db.py` — functions: `get_connection()` using `DATABASE_URL` env var, `init_db()` that creates `query_logs`, `ingestion_runs`, `ingestion_chapters` tables per data-model.md schemas, `log_query(question, answer, sources, latency_ms)`, `create_ingestion_run()`, `update_ingestion_run()`, `log_ingestion_chapter()`
- [x] T010 [P] Create Markdown-aware chunker in `backend/chunker.py` — function `chunk_markdown(filepath: str) -> list[dict]` that splits on `##`/`###` headings, extracts metadata (`part`, `part_number`, `chapter`, `section`, `chunk_index`), falls back to 1000-char splitting for long sections, returns list of dicts with `text` + metadata fields per data-model.md Qdrant payload schema
- [x] T011 Add health check endpoint `GET /health` in `backend/main.py` per contracts/openapi.yaml — checks Qdrant connectivity, Neon connectivity, and HF embedding API availability, returns `HealthResponse` with status (`healthy`/`degraded`/`unhealthy`) and per-service status

**Checkpoint**: Foundation ready — embedding client, database layer, chunker, and health check all operational. User story implementation can now begin.

---

## Phase 3: User Story 3 - Ingest Book Content (Priority: P1) — MVP Foundation

**Goal**: Author/maintainer can ingest Markdown chapters into Qdrant with rich metadata, deduplication on re-ingestion, and logging to Neon.

**Independent Test**: Run `python backend/ingest.py` or `POST /ingest`, verify passages appear in Qdrant with correct metadata, re-run and verify zero duplicates.

**Why first**: US2 (chatbot Q&A) depends on ingested content existing in Qdrant. US3 must be complete before US2 can be validated.

### Implementation for User Story 3

- [x] T012 [US3] Rewrite `backend/ingest.py` to use the new `chunker.py` and `embeddings.py` modules — replace naive 1000-char splitting with `chunk_markdown()`, replace Google `genai.embed_content` with `embed_texts()`, replace random UUIDs with deterministic IDs via `hashlib.sha256(source_path + section + chunk_index)`, implement delete-then-insert per chapter for deduplication per research.md R-006
- [x] T013 [US3] Create new Qdrant collection `textbook-passages` (384 dims, COSINE) in `backend/ingest.py` — replace old `Hackathon-book` collection (768 dims), store payload fields per data-model.md: `text`, `source`, `part`, `part_number`, `chapter`, `section`, `chunk_index`
- [x] T014 [US3] Add Neon logging to ingestion pipeline in `backend/ingest.py` — call `db.create_ingestion_run()` at start, `db.log_ingestion_chapter()` per chapter, `db.update_ingestion_run()` at completion with totals and status
- [x] T015 [US3] Add `POST /ingest` endpoint in `backend/main.py` per contracts/openapi.yaml — accepts optional `chapters` array for selective re-ingestion, calls ingestion pipeline, returns `IngestResponse` with run_id, status, totals, per-chapter results, guards against concurrent ingestion (return 409 if already running)
- [x] T016 [US3] Update `backend/ingest.py` `main()` to support both CLI (`python ingest.py`) and API invocation — detect `docs/` path relative to repo root, process all 6 parts, log progress with print statements

**Checkpoint**: Ingestion pipeline complete. All chapters ingested with rich metadata. Re-ingestion produces zero duplicates. Neon logs track every run.

---

## Phase 4: User Story 2 - Ask the RAG Chatbot a Question (Priority: P1)

**Goal**: Learner asks a question in the chat widget, receives a grounded answer with source citations within 5 seconds.

**Independent Test**: With content ingested, ask "What is a URDF model?" and verify answer cites the correct part/chapter. Ask "What is the weather?" and verify polite refusal.

### Implementation for User Story 2

- [x] T017 [US2] Rewrite `POST /query` endpoint in `backend/main.py` per contracts/openapi.yaml — use `embeddings.embed_texts()` for query embedding (HF instead of Google), search `textbook-passages` collection (top 5 results), build context from retrieved passages with source metadata, generate answer using Gemini with strict grounding system prompt
- [x] T018 [US2] Add system prompt for Gemini generation in `backend/main.py` — instruct model to: answer ONLY from provided context, cite source part and section in every answer, refuse out-of-scope questions with polite redirect, preserve book terminology per FR-006/FR-014
- [x] T019 [US2] Add query logging in `backend/main.py` — after generating response, call `db.log_query(question, answer, sources_json, latency_ms)` per FR-015
- [x] T020 [US2] Add error handling for empty knowledge base in `backend/main.py` — if Qdrant collection is empty or missing, return meaningful error message per FR-016 ("Content is being prepared, check back later")
- [x] T021 [US2] Update `src/components/ChatWidget.js` — change API URL from hardcoded `http://127.0.0.1:8000/query` to configurable endpoint, display source citations below each answer (part name + section), add loading indicator, handle error responses gracefully
- [x] T022 [US2] Format chatbot responses in `src/components/ChatWidget.js` — render answer text, show "Sources:" section with clickable links to the cited chapter/section in the textbook (use Docusaurus doc paths), style citations distinctly from answer text

**Checkpoint**: Chatbot fully functional. Grounded answers with citations. Out-of-scope refusal working. Error states handled. Query logging to Neon.

---

## Phase 5: User Story 1 - Read and Navigate the Textbook (Priority: P1)

**Goal**: Learner browses a 6-part textbook with auto-generated sidebar, clear navigation, code highlighting.

**Independent Test**: Run `npm start`, verify all 6 parts render in sidebar in order, navigate between chapters, confirm code blocks have syntax highlighting.

**Why after US2/US3**: US2 and US3 handle the backend pipeline (the hard part). US1 is primarily content and config — largely handled by T001-T004 in Setup. This phase ensures content quality and completeness.

### Implementation for User Story 1

- [x] T023 [US1] Ensure each Part directory has at least one substantive chapter with code examples — review and expand migrated content in `docs/Part-1-introduction/01-overview.md`, `docs/Part-2-humanoid-robotics/01-ros2-basics.md`, `docs/Part-3-ros2/01-nodes-topics.md`, `docs/Part-4-digital-twin/01-gazebo.md`, `docs/Part-5-vla/01-vla-overview.md`, `docs/Part-6-capstone/01-capstone-project.md`
- [x] T024 [P] [US1] Verify `_category_.json` files correctly set `position` and `label` for sidebar ordering in all 6 Part directories — Part-1 position:1 "Introduction to Physical AI", Part-2 position:2 "Basics of Humanoid Robotics", Part-3 position:3 "ROS 2 Fundamentals", Part-4 position:4 "Digital Twin Simulation", Part-5 position:5 "Vision-Language-Action Systems", Part-6 position:6 "Capstone"
- [x] T025 [US1] Update homepage at `src/pages/index.tsx` — replace generic content with book title "Humanoid Robotics: Physical AI", add hero section, and display a structured table of contents linking to each Part's landing page
- [x] T026 [US1] Update `src/css/custom.css` — ensure clean, instrument-like theme per Constitution Principle V: minimal decoration, clear typography, readable code blocks, proper sidebar width

**Checkpoint**: Textbook fully navigable. All 6 parts in sidebar. Code blocks render with syntax highlighting. Homepage links to all parts.

---

## Phase 6: User Story 4 - Module Navigation Assistance (Priority: P2)

**Goal**: Chatbot provides curriculum-aware guidance when learners ask about module order, prerequisites, and connections.

**Independent Test**: Ask "What comes after ROS 2?" and verify the chatbot recommends Digital Twin and explains the connection. Ask "How do modules connect to the Capstone?" and verify integration pipeline description.

### Implementation for User Story 4

- [x] T027 [US4] Add curriculum structure context to the Gemini system prompt in `backend/main.py` — include the 6-part structure with module relationships (Part 1 → Part 2 → Part 3 → Part 4 → Part 5 → Part 6 Capstone), module prerequisites, and the capstone integration pipeline (perception → planning → control → action)
- [x] T028 [US4] Ensure Capstone chapter content in `docs/Part-6-capstone/01-capstone-project.md` explicitly describes the integration of all modules — voice command → plan → navigate → perceive → manipulate pipeline per constitution

**Checkpoint**: Chatbot can answer curriculum navigation questions accurately. Module relationships and capstone integration clearly described.

---

## Phase 7: User Story 5 - Browse Textbook in Urdu (Priority: P3)

**Goal**: Learner can switch to Urdu locale, see translated content with RTL layout, and fall back to English for untranslated chapters.

**Independent Test**: Enable Urdu locale, navigate to a translated chapter, verify RTL rendering. Navigate to untranslated chapter, verify English fallback.

### Implementation for User Story 5

- [x] T029 [US5] Add Urdu locale configuration to `docusaurus.config.ts` — add `i18n` block with `defaultLocale: 'en'`, `locales: ['en', 'ur']`, `localeConfigs: { ur: { label: 'اردو', direction: 'rtl' } }`, add locale dropdown to navbar items
- [x] T030 [US5] Create i18n directory structure at `i18n/ur/docusaurus-plugin-content-docs/current/` — mirror `docs/` structure per data-model.md locale structure
- [x] T031 [US5] Create one sample Urdu translation in `i18n/ur/docusaurus-plugin-content-docs/current/Part-1-introduction/01-overview.md` — translate the Introduction chapter to Urdu to validate the i18n pipeline and RTL rendering
- [x] T032 [US5] Add RTL-specific CSS adjustments in `src/css/custom.css` — ensure code blocks, sidebar, and navbar render correctly in RTL mode, test with Urdu locale

**Checkpoint**: Urdu locale functional. RTL rendering correct. English fallback works for untranslated chapters. Language toggle in navbar.

---

## Phase 8: User Story 6 - Personalized Learning Chapter (Priority: P3)

**Goal**: Learner accesses a self-assessment chapter that recommends a study path based on their prior knowledge.

**Independent Test**: Navigate to personalize chapter, indicate ROS 2 experience, verify recommendation to start at Part 4. Indicate no experience, verify full sequential path recommendation.

### Implementation for User Story 6

- [x] T033 [US6] Create personalization chapter at `docs/personalize/index.mdx` — include self-assessment questionnaire covering prior knowledge areas: ROS 2, simulation (Gazebo/Unity), NVIDIA Isaac, VLA/LLMs, general robotics. Use MDX to render interactive elements
- [x] T034 [US6] Create `_category_.json` for `docs/personalize/` — set position after Part-6 (position: 7), label: "Personalize Your Learning"
- [x] T035 [US6] Define study path logic in `docs/personalize/index.mdx` — map learner profiles to recommended paths: (1) no experience → full sequential Part 1-6, (2) ROS 2 experience → start at Part 4, (3) simulation experience → start at Part 5, (4) advanced → jump to Part 6 Capstone. Use client-side JavaScript or React state for interactive recommendations

**Checkpoint**: Personalization chapter functional. Self-assessment produces valid study path for all defined learner profiles.

---

## Phase 9: Polish & Cross-Cutting Concerns

**Purpose**: Integration testing, cleanup, and validation across all stories

- [x] T036 [P] Verify end-to-end flow: `npm run build` succeeds, all 6 parts render, sidebar auto-generates correctly
- [x] T037 [P] Verify backend end-to-end: run ingestion, query chatbot, check Neon logs, check health endpoint
- [x] T038 Update `src/theme/Root.js` to ensure ChatWidget is injected globally (should already exist, verify import path matches component location)
- [x] T039 [P] Add `.gitignore` entries for `backend/.env`, `node_modules/`, `build/`, `.docusaurus/`
- [x] T040 [P] Validate quickstart.md from `specs/008-textbook-generation/quickstart.md` — run through all setup steps to confirm they work end-to-end
- [x] T041 CORS configuration in `backend/main.py` — restrict allowed origins from `*` to the GitHub Pages domain and localhost for production readiness

---

## Dependencies & Execution Order

### Phase Dependencies

- **Setup (Phase 1)**: No dependencies — can start immediately
- **Foundational (Phase 2)**: Depends on Setup (T005, T006 for deps/env) — BLOCKS all user stories
- **US3 - Ingestion (Phase 3)**: Depends on Foundational (T008 embeddings, T009 db, T010 chunker)
- **US2 - Chatbot Q&A (Phase 4)**: Depends on Foundational + US3 (needs ingested content for validation)
- **US1 - Textbook Navigation (Phase 5)**: Depends on Setup (T001-T004). Can proceed in parallel with US2/US3 for content work
- **US4 - Navigation Assistance (Phase 6)**: Depends on US2 (chatbot must work first)
- **US5 - Urdu (Phase 7)**: Depends on US1 (textbook content must exist). Independent of backend stories
- **US6 - Personalization (Phase 8)**: Depends on US1 (textbook structure must exist). Independent of backend stories
- **Polish (Phase 9)**: Depends on all desired user stories being complete

### User Story Dependencies

```
Setup (Phase 1)
    │
    ▼
Foundational (Phase 2)
    │
    ├──────────────────────────┐
    ▼                          ▼
US3 Ingestion (Phase 3)   US1 Textbook (Phase 5) ──┬──► US5 Urdu (Phase 7)
    │                                                │
    ▼                                                └──► US6 Personalize (Phase 8)
US2 Chatbot Q&A (Phase 4)
    │
    ▼
US4 Navigation (Phase 6)
    │
    ▼
Polish (Phase 9)
```

### Within Each User Story

- Models/schemas before services
- Services before endpoints
- Backend before frontend
- Core implementation before integration

### Parallel Opportunities

**Phase 1 (Setup)**:
- T003 (docusaurus config), T004 (sidebars), T005 (requirements.txt), T006 (.env.example) — all different files, run in parallel

**Phase 2 (Foundational)**:
- T008 (embeddings.py), T009 (db.py), T010 (chunker.py) — all different files, run in parallel
- T011 (health endpoint) depends on T008/T009 for connectivity checks

**Cross-story parallelism**:
- US1 (frontend/content) and US3 (backend/ingestion) can proceed in parallel after Foundational
- US5 (Urdu) and US6 (Personalization) can proceed in parallel after US1

---

## Parallel Example: Foundational Phase

```
# Launch all three foundational modules together (different files):
Task: "Create HF embedding client in backend/embeddings.py"         [T008]
Task: "Create Neon Postgres module in backend/db.py"                [T009]
Task: "Create Markdown-aware chunker in backend/chunker.py"         [T010]

# After all three complete:
Task: "Add health check endpoint in backend/main.py"               [T011]
```

## Parallel Example: After Foundational Completes

```
# Stream 1 (Backend):
Task: "Rewrite ingestion pipeline in backend/ingest.py"            [T012]
Task: "Create Qdrant collection in backend/ingest.py"              [T013]
...

# Stream 2 (Frontend/Content) — can run simultaneously:
Task: "Ensure each Part has substantive chapters in docs/"          [T023]
Task: "Verify _category_.json sidebar ordering in docs/Part-*/..."  [T024]
...
```

---

## Implementation Strategy

### MVP First (US3 + US2 = Working Chatbot)

1. Complete Phase 1: Setup (restructure, config)
2. Complete Phase 2: Foundational (embeddings, db, chunker, health)
3. Complete Phase 3: US3 — Ingestion pipeline
4. Complete Phase 4: US2 — Chatbot Q&A
5. **STOP and VALIDATE**: Ingest content, ask questions, verify grounded answers with citations
6. Deploy if ready — this is the core MVP

### Incremental Delivery

1. Setup + Foundational → Foundation ready
2. US3 (Ingestion) → Content in Qdrant ✓
3. US2 (Chatbot) → Interactive Q&A working ✓ → **Deploy MVP**
4. US1 (Navigation) → Polished textbook experience ✓
5. US4 (Module Nav) → Curriculum guidance ✓
6. US5 (Urdu) → Accessibility ✓
7. US6 (Personalize) → Enhanced onboarding ✓
8. Polish → Production-ready ✓

### Suggested MVP Scope

**MVP = Phase 1 + Phase 2 + Phase 3 + Phase 4** (T001–T022)
This delivers a working textbook with a RAG chatbot that answers questions with citations.

---

## Summary

| Metric | Value |
|--------|-------|
| **Total tasks** | 41 |
| **Phase 1 (Setup)** | 7 tasks (T001–T007) |
| **Phase 2 (Foundational)** | 4 tasks (T008–T011) |
| **Phase 3 (US3 - Ingestion)** | 5 tasks (T012–T016) |
| **Phase 4 (US2 - Chatbot)** | 6 tasks (T017–T022) |
| **Phase 5 (US1 - Navigation)** | 4 tasks (T023–T026) |
| **Phase 6 (US4 - Module Nav)** | 2 tasks (T027–T028) |
| **Phase 7 (US5 - Urdu)** | 4 tasks (T029–T032) |
| **Phase 8 (US6 - Personalize)** | 3 tasks (T033–T035) |
| **Phase 9 (Polish)** | 6 tasks (T036–T041) |
| **Parallel opportunities** | 14 tasks marked [P] |
| **MVP tasks** | 22 (T001–T022) |

---

## Notes

- [P] tasks = different files, no dependencies on incomplete tasks
- [Story] label maps task to specific user story for traceability
- Each user story is independently completable and testable
- Commit after each task or logical group
- Stop at any checkpoint to validate story independently
- US3 (Ingestion) intentionally ordered before US2 (Chatbot) because chatbot needs ingested content
